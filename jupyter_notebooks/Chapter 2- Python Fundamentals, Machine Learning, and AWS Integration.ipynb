{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9753afe1",
   "metadata": {},
   "source": [
    "# Chapter 2: Python Fundamentals, Machine Learning, and AWS Integration\n",
    "\n",
    "## Part 1: Python Fundamentals\n",
    "\n",
    "### 1.1 Setting Up Python\n",
    "\n",
    "1. Visit https://www.python.org/downloads/\n",
    "2. Download and install the latest version of Python for your operating system\n",
    "3. Verify installation by opening a terminal/command prompt and typing:\n",
    "   ```\n",
    "   python --version\n",
    "   ```\n",
    "\n",
    "### 1.2 Python Basics\n",
    "\n",
    "#### Variables and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5  # integer\n",
    "y = 3.14  # float\n",
    "name = \"Alice\"  # string\n",
    "is_student = True  # boolean\n",
    "\n",
    "print(f\"x: {x}, y: {y}, name: {name}, is_student: {is_student}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05115e",
   "metadata": {},
   "source": [
    "#### Control Structures\n",
    "\n",
    "##### If Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fe488",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 20\n",
    "if age < 18:\n",
    "    print(\"Minor\")\n",
    "elif age >= 18 and age < 65:\n",
    "    print(\"Adult\")\n",
    "else:\n",
    "    print(\"Senior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0240a",
   "metadata": {},
   "source": [
    "##### Loops\n",
    "\n",
    "###### For Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ee05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over a list\n",
    "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
    "for fruit in fruits:\n",
    "    print(fruit)\n",
    "\n",
    "# Using range\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "# Iterating over a dictionary\n",
    "person = {\"name\": \"Bob\", \"age\": 30, \"city\": \"New York\"}\n",
    "for key, value in person.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98f0a0",
   "metadata": {},
   "source": [
    "###### While Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79346258",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while count < 5:\n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9b38a",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c67bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name):\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "print(greet(\"World\"))\n",
    "\n",
    "# Function with default parameter\n",
    "def power(base, exponent=2):\n",
    "    return base ** exponent\n",
    "\n",
    "print(power(3))  # 9\n",
    "print(power(3, 3))  # 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddbce04",
   "metadata": {},
   "source": [
    "### 1.3 Data Structures\n",
    "\n",
    "#### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
    "print(fruits[0])  # apple\n",
    "fruits.append(\"date\")\n",
    "print(fruits)  # ['apple', 'banana', 'cherry', 'date']\n",
    "fruits.remove(\"banana\")\n",
    "print(fruits)  # ['apple', 'cherry', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041bca11",
   "metadata": {},
   "source": [
    "#### Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4362642",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = (3, 4)\n",
    "x, y = coordinates\n",
    "print(f\"x: {x}, y: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57410fc1",
   "metadata": {},
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n",
    "print(person[\"name\"])  # Alice\n",
    "person[\"job\"] = \"Engineer\"\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd59ada",
   "metadata": {},
   "source": [
    "#### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = {\"apple\", \"banana\", \"cherry\"}\n",
    "fruits.add(\"date\")\n",
    "print(fruits)\n",
    "fruits.remove(\"banana\")\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12bb4c",
   "metadata": {},
   "source": [
    "## Part 2: Python for Data Science and Machine Learning\n",
    "\n",
    "### 2.1 Introduction to NumPy\n",
    "\n",
    "First, install NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a441af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd91aa",
   "metadata": {},
   "source": [
    "Basic NumPy operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create arrays\n",
    "arr1 = np.array([1, 2, 3, 4, 5])\n",
    "arr2 = np.array([6, 7, 8, 9, 10])\n",
    "\n",
    "print(\"Array 1:\", arr1)\n",
    "print(\"Array 2:\", arr2)\n",
    "\n",
    "# Basic operations\n",
    "print(\"Sum:\", arr1 + arr2)\n",
    "print(\"Multiplication:\", arr1 * arr2)\n",
    "\n",
    "# Statistical operations\n",
    "print(\"Mean of arr1:\", np.mean(arr1))\n",
    "print(\"Standard deviation of arr2:\", np.std(arr2))\n",
    "\n",
    "# Reshaping\n",
    "matrix = arr1.reshape(5, 1)\n",
    "print(\"Reshaped array:\\n\", matrix)\n",
    "\n",
    "# Linear algebra\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "print(\"Matrix multiplication:\\n\", np.dot(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98cbd02",
   "metadata": {},
   "source": [
    "### 2.2 Introduction to Pandas\n",
    "\n",
    "Install Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fbc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a683ee",
   "metadata": {},
   "source": [
    "Let's explore Pandas with more detailed examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Age': [28, 34, 29, 32],\n",
    "    'City': ['New York', 'Paris', 'Berlin', 'London'],\n",
    "    'Salary': [50000, 60000, 55000, 75000]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Basic information about the DataFrame\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Selecting columns\n",
    "print(\"\\nNames and Ages:\")\n",
    "print(df[['Name', 'Age']])\n",
    "\n",
    "# Filtering rows\n",
    "print(\"\\nPeople older than 30:\")\n",
    "print(df[df['Age'] > 30])\n",
    "\n",
    "# Adding a new column\n",
    "df['Experience'] = [3, 8, 4, 10]\n",
    "print(\"\\nDataFrame with new 'Experience' column:\")\n",
    "print(df)\n",
    "\n",
    "# Group by and aggregate\n",
    "print(\"\\nAverage Salary by City:\")\n",
    "print(df.groupby('City')['Salary'].mean())\n",
    "\n",
    "# Sorting\n",
    "print(\"\\nSorted by Age (descending):\")\n",
    "print(df.sort_values('Age', ascending=False))\n",
    "\n",
    "# Handling missing values\n",
    "df.loc[1, 'Salary'] = np.nan\n",
    "print(\"\\nDataFrame with missing value:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDropping rows with missing values:\")\n",
    "print(df.dropna())\n",
    "\n",
    "print(\"\\nFilling missing values with mean:\")\n",
    "print(df.fillna(df.mean()))\n",
    "\n",
    "# Date handling\n",
    "df['Date'] = pd.date_range('2023-01-01', periods=4)\n",
    "print(\"\\nDataFrame with dates:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nExtracting year from date:\")\n",
    "print(df['Date'].dt.year)\n",
    "\n",
    "# Reading and writing data\n",
    "df.to_csv('employees.csv', index=False)\n",
    "df_read = pd.read_csv('employees.csv')\n",
    "print(\"\\nData read from CSV:\")\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92f109",
   "metadata": {},
   "source": [
    "### 2.3 Introduction to Scikit-learn\n",
    "\n",
    "Install Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e041e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed933ec",
   "metadata": {},
   "source": [
    "Let's explore Scikit-learn with more detailed examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b547159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load a dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "print(\"Iris Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, lr_pred, target_names=iris.target_names))\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, dt_pred, target_names=iris.target_names))\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rf_pred, target_names=iris.target_names))\n",
    "\n",
    "# Feature Importance (for Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': iris.feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191adaba",
   "metadata": {},
   "source": [
    "## Part 3: AWS Integration\n",
    "\n",
    "### 3.1 Setting Up AWS SDK for Python (Boto3)\n",
    "\n",
    "1. Open a terminal/command prompt\n",
    "2. Install Boto3 using pip:\n",
    "   ```\n",
    "   pip install boto3\n",
    "   ```\n",
    "3. Create a new Python file named `aws_example.py`\n",
    "\n",
    "### 3.2 Configuring AWS Credentials\n",
    "\n",
    "1. Create a file named `credentials` in `~/.aws/` (Linux/Mac) or `C:\\Users\\YOUR_USERNAME\\.aws\\` (Windows)\n",
    "2. Add your AWS credentials to this file:\n",
    "   ```\n",
    "   [default]\n",
    "   aws_access_key_id = YOUR_ACCESS_KEY\n",
    "   aws_secret_access_key = YOUR_SECRET_KEY\n",
    "   ```\n",
    "   Replace `YOUR_ACCESS_KEY` and `YOUR_SECRET_KEY` with your actual AWS credentials.\n",
    "\n",
    "### 3.3 Basic AWS Operations with Python\n",
    "\n",
    "#### Listing S3 Buckets\n",
    "\n",
    "Add the following code to `aws_example.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da22bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List S3 buckets\n",
    "response = s3.list_buckets()\n",
    "\n",
    "print(\"S3 Buckets:\")\n",
    "for bucket in response['Buckets']:\n",
    "    print(f\"- {bucket['Name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316604b",
   "metadata": {},
   "source": [
    "Run the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f419737",
   "metadata": {},
   "outputs": [],
   "source": [
    "python aws_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e3565",
   "metadata": {},
   "source": [
    "#### Uploading a File to S3\n",
    "\n",
    "Add this function to `aws_example.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8fd658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        s3_client.upload_file(file_name, bucket, object_name)\n",
    "        print(f\"File {file_name} uploaded successfully to {bucket}/{object_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Usage\n",
    "upload_file('sample.txt', 'your-bucket-name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33cb0f",
   "metadata": {},
   "source": [
    "Replace `'your-bucket-name'` with your actual bucket name.\n",
    "\n",
    "#### Launching an EC2 Instance\n",
    "\n",
    "Add this function to `aws_example.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174347c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_ec2_instance():\n",
    "    ec2 = boto3.resource('ec2')\n",
    "    \n",
    "    instances = ec2.create_instances(\n",
    "        ImageId='ami-0aa7d40eeae50c9a9',  # Amazon Linux 2 AMI ID, may vary by region\n",
    "        MinCount=1,\n",
    "        MaxCount=1,\n",
    "        InstanceType='t2.micro',\n",
    "        KeyName='your-key-pair-name'  # Replace with your key pair name\n",
    "    )\n",
    "    \n",
    "    print(f\"New instance created: {instances[0].id}\")\n",
    "\n",
    "# Usage\n",
    "launch_ec2_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ed308",
   "metadata": {},
   "source": [
    "Replace `'your-key-pair-name'` with the name of your EC2 key pair.\n",
    "\n",
    "### 3.4 Using AWS Data Wrangler\n",
    "\n",
    "Install AWS Data Wrangler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97940b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install awswrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7cc5e",
   "metadata": {},
   "source": [
    "Let's explore some examples of using AWS Data Wrangler with various AWS services:\n",
    "\n",
    "#### 3.4.1 Working with Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8246c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'age': [25, 30, 35]\n",
    "})\n",
    "\n",
    "# Write DataFrame to S3 as a CSV file\n",
    "wr.s3.to_csv(\n",
    "    df=df,\n",
    "    path='s3://your-bucket-name/employees.csv'\n",
    ")\n",
    "print(\"Data written to S3\")\n",
    "\n",
    "# Read CSV from S3\n",
    "df_read = wr.s3.read_csv('s3://your-bucket-name/employees.csv')\n",
    "print(\"Data read from S3:\")\n",
    "print(df_read)\n",
    "\n",
    "# List objects in an S3 bucket\n",
    "objects = wr.s3.list_objects('s3://your-bucket-name/')\n",
    "print(\"Objects in bucket:\")\n",
    "for obj in objects:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24353c61",
   "metadata": {},
   "source": [
    "#### 3.4.2 Working with Amazon Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab65ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to an AWS Glue Data Catalog / Amazon Athena\n",
    "wr.s3.to_parquet(\n",
    "    df=df,\n",
    "    path='s3://your-bucket-name/employees_parquet/',\n",
    "    dataset=True,\n",
    "    database='your_database',\n",
    "    table='employees'\n",
    ")\n",
    "print(\"Data written to Glue Data Catalog\")\n",
    "\n",
    "# Read data from Athena\n",
    "df_athena = wr.athena.read_sql_query(\n",
    "    \"SELECT * FROM employees WHERE age > 30\",\n",
    "    database='your_database'\n",
    ")\n",
    "print(\"Data read from Athena:\")\n",
    "print(df_athena)\n",
    "\n",
    "# Get the query execution details\n",
    "query_execution_id = wr.athena.start_query_execution(\n",
    "    sql=\"SELECT * FROM employees\",\n",
    "    database='your_database'\n",
    ")\n",
    "details = wr.athena.get_query_execution(query_execution_id)\n",
    "print(\"Query execution details:\", details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fe969",
   "metadata": {},
   "source": [
    "#### 3.4.3 Working with AWS Glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all databases in Glue Data Catalog\n",
    "databases = wr.catalog.databases()\n",
    "print(\"Glue databases:\", databases)\n",
    "\n",
    "# List all tables in a specific database\n",
    "tables = wr.catalog.tables(database='your_database')\n",
    "print(\"Tables in your_database:\", tables)\n",
    "\n",
    "# Get the schema of a specific table\n",
    "schema = wr.catalog.table(database='your_database', table='employees')\n",
    "print(\"Schema of employees table:\", schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05445db0",
   "metadata": {},
   "source": [
    "#### 3.4.4 Working with Amazon Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a Redshift cluster set up\n",
    "connection_string = \"redshift+psycopg2://username:password@host:port/database\"\n",
    "\n",
    "# Write DataFrame to Redshift\n",
    "wr.redshift.to_sql(\n",
    "    df=df,\n",
    "    table='employees',\n",
    "    schema='public',\n",
    "    con=connection_string,\n",
    "    mode='overwrite'\n",
    ")\n",
    "print(\"Data written to Redshift\")\n",
    "\n",
    "# Read data from Redshift\n",
    "df_redshift = wr.redshift.read_sql_query(\n",
    "    sql=\"SELECT * FROM public.employees\",\n",
    "    con=connection_string\n",
    ")\n",
    "print(\"Data read from Redshift:\")\n",
    "print(df_redshift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de722fc0",
   "metadata": {},
   "source": [
    "#### 3.4.5 Working with Amazon QuickSight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a QuickSight dataset from an Athena table\n",
    "response = wr.quicksight.create_athena_dataset(\n",
    "    name=\"EmployeesDataset\",\n",
    "    database='your_database',\n",
    "    table='employees',\n",
    "    account_id='your-aws-account-id',\n",
    "    region='your-aws-region'\n",
    ")\n",
    "print(\"QuickSight dataset created:\", response)\n",
    "\n",
    "# List QuickSight datasets\n",
    "datasets = wr.quicksight.list_datasets(account_id='your-aws-account-id')\n",
    "print(\"QuickSight datasets:\", datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49bb073",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this comprehensive tutorial, we've covered:\n",
    "1. Python fundamentals, including data structures and control flow\n",
    "2. Introduction to machine learning libraries: NumPy, Pandas, and Scikit-learn\n",
    "3. AWS integration using Boto3 and AWS Data Wrangler\n",
    "\n",
    "We've explored how to use AWS Data Wrangler with various AWS services, including:\n",
    "-"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
